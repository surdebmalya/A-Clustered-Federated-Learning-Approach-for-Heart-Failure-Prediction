{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-mQy4uoPJ_V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrPxr0-XWTmz",
        "outputId": "4b158b33-2779-43d1-cdb7-efa20773c8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset link: [subset of research dataset](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction/)"
      ],
      "metadata": {
        "id": "4Jj8_4EjsTmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/thesis/dataset/preprocessed_data.csv')\n",
        "data = data[data.columns[1:]]\n",
        "\n",
        "# # making testing data: last 100 unseen\n",
        "# test_data = data.loc[data.shape[0]-100:]\n",
        "# data = data[:data.shape[0]-101]"
      ],
      "metadata": {
        "id": "e2w-wjVRWVP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataDistribution:\n",
        "  def __init__(self, showing_intermediate_steps = False):\n",
        "    self.showing_intermediate_steps = showing_intermediate_steps\n",
        "    self.synthetically_distributed_data = None\n",
        "\n",
        "  def error_handling(self, splitting, number_of_clusters):\n",
        "    sum = 0\n",
        "    for i in splitting:\n",
        "      sum+=i\n",
        "    if len(splitting)==number_of_clusters and sum==1.0:\n",
        "      return True\n",
        "    else:\n",
        "      return False\n",
        "\n",
        "  def scale_training_X(self, x):\n",
        "    scaling = StandardScaler()\n",
        "    x = scaling.fit_transform(x)\n",
        "    return x\n",
        "\n",
        "  def setup(self, data, number_of_clusters, number_of_clients_in_each_cluster, splitting):\n",
        "    if self.error_handling(splitting, number_of_clusters)==False:\n",
        "      raise Exception(f\"there is some error in splitting, please follow the standards\")\n",
        "\n",
        "    splitting.pop()\n",
        "    total_data = data.shape[0]\n",
        "    temp_index = []\n",
        "    count = 0\n",
        "    for frac in splitting:\n",
        "      count += frac\n",
        "      temp_index.append(math.floor(count*total_data))\n",
        "    temp_index.append(total_data-1)\n",
        "    splitting = temp_index\n",
        "\n",
        "    if self.showing_intermediate_steps:\n",
        "      print(splitting)\n",
        "\n",
        "    splitting_index = []\n",
        "    starting = 0\n",
        "    for i in splitting:\n",
        "      temp = [starting, i]\n",
        "      starting = i + 1\n",
        "      splitting_index.append(temp)\n",
        "\n",
        "    if self.showing_intermediate_steps:\n",
        "      print(splitting_index)\n",
        "\n",
        "    splitting_index_with_cluster_clients = []\n",
        "    for cluster_index in splitting_index:\n",
        "      starting = cluster_index[0]\n",
        "      ending = cluster_index[1]\n",
        "      data_per_client = math.floor((ending-starting+1) / number_of_clients_in_each_cluster)\n",
        "      subending = starting\n",
        "      for _ in range(number_of_clients_in_each_cluster):\n",
        "        subending += data_per_client\n",
        "        temp = [starting, subending]\n",
        "        splitting_index_with_cluster_clients.append(temp)\n",
        "        starting = subending + 1\n",
        "\n",
        "    if self.showing_intermediate_steps:\n",
        "      print(splitting_index_with_cluster_clients)\n",
        "\n",
        "    curr_counter = 0\n",
        "    cluster_client_data = []\n",
        "    for i in range(number_of_clusters):\n",
        "      cluster_data = []\n",
        "      for j in range(number_of_clients_in_each_cluster):\n",
        "        starting_index = splitting_index_with_cluster_clients[curr_counter][0]\n",
        "        ending_index = splitting_index_with_cluster_clients[curr_counter][1]\n",
        "        curr_client_data = data.loc[starting_index:ending_index]\n",
        "        x = curr_client_data.drop('HeartDisease',axis=1)\n",
        "        y = curr_client_data.HeartDisease\n",
        "        x = self.scale_training_X(x)\n",
        "        curr_client_data_X_Y = [x, y]\n",
        "        curr_counter += 1\n",
        "        cluster_data.append(curr_client_data_X_Y)\n",
        "      cluster_client_data.append(cluster_data)\n",
        "\n",
        "    self.synthetically_distributed_data = cluster_client_data\n",
        "    print(f\"data distributed synthetically!\")"
      ],
      "metadata": {
        "id": "ob6hx5m2WVIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "class Model:\n",
        "  def __init__(self):\n",
        "    m = LogisticRegression()\n",
        "    self.model = m\n",
        "\n",
        "  def fit(self, x_train, y_train):\n",
        "    self.model.fit(x_train, y_train)\n",
        "\n",
        "  def score(self, x, y):\n",
        "    return self.model.score(x, y)\n",
        "\n",
        "  def get_coef(self):\n",
        "    print(self.model.coef_)"
      ],
      "metadata": {
        "id": "3JUqrCy-WVCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleModelCFL:\n",
        "  def __init__(self, data, number_of_clusters, number_of_clients_in_each_cluster, number_of_clusters_every_iteration, splitting):\n",
        "    self.number_of_clusters = number_of_clusters\n",
        "    self.number_of_clients_in_each_cluster = number_of_clients_in_each_cluster\n",
        "    self.number_of_clusters_every_iteration = number_of_clusters_every_iteration\n",
        "    self.splitting = splitting\n",
        "    if self.error_handling()==False:\n",
        "      raise Exception(f\"something went wrong, please follow the standards\")\n",
        "    data_dist = DataDistribution()\n",
        "    data_dist.setup(data, self.number_of_clusters, self.number_of_clients_in_each_cluster, self.splitting)\n",
        "    self.synthetically_distributed_data = data_dist\n",
        "    print(f\"setup is ready to be executed!\")\n",
        "\n",
        "  def error_handling(self):\n",
        "    if(self.number_of_clusters<=0 or \\\n",
        "       self.number_of_clients_in_each_cluster<=0 or \\\n",
        "       self.number_of_clusters_every_iteration<=0 or \\\n",
        "       self.number_of_clusters_every_iteration>self.number_of_clusters):\n",
        "      return False\n",
        "\n",
        "  def cluster_selection_algo(self):\n",
        "    selected_clusters = []\n",
        "    count = 0\n",
        "    while(count<self.number_of_clusters_every_iteration):\n",
        "      current_cluster_number = random.randint(0, self.number_of_clusters-1)\n",
        "      if current_cluster_number not in selected_clusters:\n",
        "        selected_clusters.append(current_cluster_number)\n",
        "        count = count + 1\n",
        "    return selected_clusters\n",
        "\n",
        "  def client_level_aggregation_algo(self, client_level_models):\n",
        "    result = client_level_models[0]\n",
        "    for i in range(len(client_level_models)):\n",
        "      result = np.add(result, client_level_models[i])\n",
        "    result = result / len(client_level_models)\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "  def cluster_level_aggregation_algo(self, cluster_level_models):\n",
        "    result = cluster_level_models[0]\n",
        "    for i in range(len(cluster_level_models)):\n",
        "      result = np.add(result, cluster_level_models[i])\n",
        "    result = result / len(cluster_level_models)\n",
        "    self.global_model.model.coef_ = result\n",
        "\n",
        "  def execute(self, number_of_iterations):\n",
        "    self.global_model = Model()\n",
        "    count = 0\n",
        "    for itr in range(number_of_iterations):\n",
        "      current_model = self.global_model\n",
        "      cluster_indices = self.cluster_selection_algo()\n",
        "      cluster_level_models = []\n",
        "      for cluster_index in cluster_indices:\n",
        "        client_level_models = []\n",
        "        for client_index in range(self.number_of_clients_in_each_cluster):\n",
        "          current_client_data = self.synthetically_distributed_data.synthetically_distributed_data[cluster_index][client_index]\n",
        "          current_client_X = current_client_data[0]\n",
        "          current_client_Y = current_client_data[1]\n",
        "          current_model.fit(current_client_X, current_client_Y)\n",
        "          s = current_model.score(current_client_X, current_client_Y)\n",
        "          print(f\"iteration: {count+1} || cluster number: {cluster_index+1} || client number: {client_index+1} || score: {s}\")\n",
        "          count += 1\n",
        "          client_level_models.append(current_model.model.coef_)\n",
        "        coef = self.client_level_aggregation_algo(client_level_models)\n",
        "        cluster_level_models.append(coef)\n",
        "      self.cluster_level_aggregation_algo(cluster_level_models)\n",
        "    print(f\"architecture executed successfully!\")\n",
        "\n",
        "  def _scale_training_X(self, x):\n",
        "    scaling = StandardScaler()\n",
        "    x = scaling.fit_transform(x)\n",
        "    return x\n",
        "\n",
        "  def predict(self, df):\n",
        "    x = df.drop('HeartDisease',axis=1)\n",
        "    y = df.HeartDisease\n",
        "    x = self._scale_training_X(x)\n",
        "    s = self.global_model.score(x, y)\n",
        "    return s"
      ],
      "metadata": {
        "id": "N1sDWSfYpFUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfl = SingleModelCFL(data, 2, 3, 1, [0.7, 0.3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zySz2C-zvf0z",
        "outputId": "c991876a-7de3-4a4f-c4e3-a600dc62a79f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data distributed synthetically!\n",
            "setup is ready to be executed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfl.execute(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ke6QSWAmwZlQ",
        "outputId": "d111a825-5718-40a4-996a-a7bd1d3418db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration: 1 || cluster number: 1 || client number: 1 || score: 0.9395348837209302\n",
            "iteration: 2 || cluster number: 1 || client number: 2 || score: 0.9485981308411215\n",
            "iteration: 3 || cluster number: 1 || client number: 3 || score: 0.883177570093458\n",
            "[[-0.27753848 -0.64744857  0.66778512  0.43264476 -0.27790983  0.99663526\n",
            "   0.06661761 -0.37546509 -0.24620124  0.23860198  2.88884049]]\n",
            "iteration: 4 || cluster number: 2 || client number: 1 || score: 0.8369565217391305\n",
            "iteration: 5 || cluster number: 2 || client number: 2 || score: 0.8901098901098901\n",
            "iteration: 6 || cluster number: 2 || client number: 3 || score: 0.8571428571428571\n",
            "[[ 0.06690286 -1.27495467  1.28864523  0.54563819  0.44051512 -0.18871797\n",
            "   0.33147569 -0.90981043 -0.4970101   0.38544738  0.58834437]]\n",
            "iteration: 7 || cluster number: 1 || client number: 1 || score: 0.9395348837209302\n",
            "iteration: 8 || cluster number: 1 || client number: 2 || score: 0.9485981308411215\n",
            "iteration: 9 || cluster number: 1 || client number: 3 || score: 0.883177570093458\n",
            "[[-0.27753848 -0.64744857  0.66778512  0.43264476 -0.27790983  0.99663526\n",
            "   0.06661761 -0.37546509 -0.24620124  0.23860198  2.88884049]]\n",
            "architecture executed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cfl.predict(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHj5nh2i3nDJ",
        "outputId": "488b83b0-b6d3-445e-c60a-e13f37979a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8376906318082789"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIB5pxQo8r56"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}